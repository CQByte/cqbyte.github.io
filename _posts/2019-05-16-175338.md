 - [x] List item

---
layout: post
title: 爬虫-杂记
subtitle:
date: 2019-05-16
tags: ['杂记']
---
## 概念
爬虫（又称网络爬虫、网页蜘蛛、网络机器人）是一种自动抓取万维网信息（自动提取网页内容）的程序或脚本。

按抓取目的分为通用网络爬虫（覆盖式地爬取网页信息）和聚焦爬虫（定向抓取相关网页资源，有选择地爬取相关链接）。

## 功能
高效地批量下载目标网站数据，是搜索引擎的重要模块。

## 工作原理
简单来说爬虫会访问一个 URL ，获取其中的数据进行处理，此外还会解析出其中包含的其他 URL，并按一定规则访问这些URL，如此重复直到达到某个条件。

初始URL从哪来？
对于搜索引擎来说有以下几种：
- 网站主动提交
- 在其他网站上设置外链
- 从DNS解析服务商那里获取

### 通用爬虫工作流程
1. 通过 DNS 解析 URL 获取对应 IP，
2. 下载器下载页面
3. 存储网页到本地
4. 把当前 URL 存到已下载 URL 队列，避免重复下载
5. 解析 3 中的网页获取新的 URL ，判定需要下载就放到等待下载的 URL 队列中
6. 

## 爬虫禁抓协议和网页禁抓标记
爬虫禁抓协议指的是由网站所有者生成一个指定的文件robot.txt，并放在网站服务器的根目录下，这个文件指明了网站中哪些目录下的网页是不允许爬虫抓取的。具有友好性的爬虫在抓取该网站的网页前，首先要读取robot.txt文件，对于禁止抓取的网页不进行下载。

网页禁抓标记一般在网页的HTML代码里加入meta name="robots”标记，content字段指出允许或者不允许爬虫的哪些行为。可以分为两种情形，一种是告知爬虫不要索引该网页内容，以noindex作为标记；另外一种情形是告知爬虫不要抓取网页所包含的链接，以nofollow作为标记。通过这种方式，可以达到对网页内容的一种隐私保护。
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTQ4NzkxOTIwMl19
-->